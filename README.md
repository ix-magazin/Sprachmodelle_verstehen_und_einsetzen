# Sprachmodelle_verstehen_und_einsetzen
Jupyter-Notebook zum [Sonderheft-Artikel](https://www.heise.de/select/ix/2023/13/2302013462923862371) von Prof. Christian Winkler, erschienen im [iX Special 2023](https://www.heise.de/select/ix/2022/13/).

# iX-tract
- Große Sprachmodelle (LLMs) wandeln Wörter in Token und diese in kontextualisierte Vektor-Embeddings um.
- Durch die Ähnlichkeit von Wort-Embeddings erkennen die Systeme den Kontext von Wörtern, Sätzen und ganzen Dokumenten.
- Generative Sprachmodelle stehen aktuell stark im Fokus. Sie erzeugen auf Basis statistischer Vorhersagen kontextuell passende Texte.
- Mit LLMs lässt sich Text auf vielfältige Weise verändern, analysieren oder erstellen: Sentiment Detection, Named Entity Recognition und Textzusammenfassen sind nur ein Bruchteil dieser Fähigkeiten.
